{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5ceb4f19",
   "metadata": {},
   "source": [
    "# Importing and Displaying Data from a TSV File Using Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6946319b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>event</th>\n",
       "      <th>ts1</th>\n",
       "      <th>ts2</th>\n",
       "      <th>from_stream</th>\n",
       "      <th>directly_from_stream</th>\n",
       "      <th>from_search</th>\n",
       "      <th>directly_from_search</th>\n",
       "      <th>from_quote_search</th>\n",
       "      <th>directly_from_quote_search</th>\n",
       "      <th>...</th>\n",
       "      <th>retweeted</th>\n",
       "      <th>retweeted_author_id</th>\n",
       "      <th>retweeted_handle</th>\n",
       "      <th>retweeted_follower_count</th>\n",
       "      <th>mentioned_author_ids</th>\n",
       "      <th>mentioned_handles</th>\n",
       "      <th>hashtags</th>\n",
       "      <th>urls</th>\n",
       "      <th>media_keys</th>\n",
       "      <th>place_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1131594960443199488</td>\n",
       "      <td>britney_201904</td>\n",
       "      <td>2022-02-28 09:34:44.627023-05:00</td>\n",
       "      <td>2022-02-28 09:34:44.627023-05:00</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>1130917791752757254</td>\n",
       "      <td>3042894016</td>\n",
       "      <td>Iesbwian</td>\n",
       "      <td>22760</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1131594976750653440</td>\n",
       "      <td>britney_201904</td>\n",
       "      <td>2022-02-28 09:34:44.626921-05:00</td>\n",
       "      <td>2022-02-28 09:34:44.626921-05:00</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1131589737955942405</td>\n",
       "      <td>britney_201904</td>\n",
       "      <td>2022-02-28 09:34:44.634058-05:00</td>\n",
       "      <td>2022-02-28 09:34:44.634058-05:00</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1131594909469892610</td>\n",
       "      <td>britney_201904</td>\n",
       "      <td>2022-02-28 09:34:44.627125-05:00</td>\n",
       "      <td>2022-02-28 09:34:44.627125-05:00</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>1130917791752757254</td>\n",
       "      <td>3042894016</td>\n",
       "      <td>Iesbwian</td>\n",
       "      <td>22760</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1131594812694511617</td>\n",
       "      <td>britney_201904</td>\n",
       "      <td>2022-02-28 09:34:44.627227-05:00</td>\n",
       "      <td>2022-02-28 09:34:44.627227-05:00</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>...</td>\n",
       "      <td>1130917791752757254</td>\n",
       "      <td>3042894016</td>\n",
       "      <td>Iesbwian</td>\n",
       "      <td>22760</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 46 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    id           event                               ts1  \\\n",
       "0  1131594960443199488  britney_201904  2022-02-28 09:34:44.627023-05:00   \n",
       "1  1131594976750653440  britney_201904  2022-02-28 09:34:44.626921-05:00   \n",
       "2  1131589737955942405  britney_201904  2022-02-28 09:34:44.634058-05:00   \n",
       "3  1131594909469892610  britney_201904  2022-02-28 09:34:44.627125-05:00   \n",
       "4  1131594812694511617  britney_201904  2022-02-28 09:34:44.627227-05:00   \n",
       "\n",
       "                                ts2  from_stream  directly_from_stream  \\\n",
       "0  2022-02-28 09:34:44.627023-05:00         True                  True   \n",
       "1  2022-02-28 09:34:44.626921-05:00         True                  True   \n",
       "2  2022-02-28 09:34:44.634058-05:00         True                  True   \n",
       "3  2022-02-28 09:34:44.627125-05:00         True                  True   \n",
       "4  2022-02-28 09:34:44.627227-05:00         True                  True   \n",
       "\n",
       "   from_search  directly_from_search  from_quote_search  \\\n",
       "0        False                 False              False   \n",
       "1        False                 False              False   \n",
       "2        False                 False              False   \n",
       "3        False                 False              False   \n",
       "4        False                 False              False   \n",
       "\n",
       "   directly_from_quote_search  ...            retweeted  retweeted_author_id  \\\n",
       "0                       False  ...  1130917791752757254           3042894016   \n",
       "1                       False  ...                 None                 None   \n",
       "2                       False  ...                 None                 None   \n",
       "3                       False  ...  1130917791752757254           3042894016   \n",
       "4                       False  ...  1130917791752757254           3042894016   \n",
       "\n",
       "   retweeted_handle  retweeted_follower_count mentioned_author_ids  \\\n",
       "0          Iesbwian                     22760                 None   \n",
       "1              None                      None                 None   \n",
       "2              None                      None                 None   \n",
       "3          Iesbwian                     22760                 None   \n",
       "4          Iesbwian                     22760                 None   \n",
       "\n",
       "  mentioned_handles  hashtags  urls media_keys  place_id  \n",
       "0              None      None  None       None      None  \n",
       "1              None      None  None       None      None  \n",
       "2              None      None  None       None      None  \n",
       "3              None      None  None       None      None  \n",
       "4              None      None  None       None      None  \n",
       "\n",
       "[5 rows x 46 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Replace 'file.tsv' with the actual path of a file\n",
    "file_path = r\"C:\\Users\\hp\\Downloads\\correct_twitter_201904.tsv\"\n",
    "# Reading the TSV file\n",
    "df = pd.read_csv(file_path, sep='\\t')\n",
    "\n",
    "# Display the first few rows of the DataFrame\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0b73c667",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 88037 entries, 0 to 88036\n",
      "Data columns (total 46 columns):\n",
      " #   Column                         Non-Null Count  Dtype \n",
      "---  ------                         --------------  ----- \n",
      " 0   id                             88037 non-null  int64 \n",
      " 1   event                          88037 non-null  object\n",
      " 2   ts1                            88037 non-null  object\n",
      " 3    ts2                           88037 non-null  object\n",
      " 4   from_stream                    88037 non-null  bool  \n",
      " 5   directly_from_stream           88037 non-null  bool  \n",
      " 6   from_search                    88037 non-null  bool  \n",
      " 7   directly_from_search           88037 non-null  bool  \n",
      " 8   from_quote_search              88037 non-null  bool  \n",
      " 9   directly_from_quote_search     88037 non-null  bool  \n",
      " 10  from_convo_search              88037 non-null  bool  \n",
      " 11  directly_from_convo_search     88037 non-null  bool  \n",
      " 12  from_timeline_search           88037 non-null  bool  \n",
      " 13  directly_from_timeline_search  88037 non-null  bool  \n",
      " 14  text                           88037 non-null  object\n",
      " 15  lang                           88037 non-null  object\n",
      " 16  author_id                      88037 non-null  int64 \n",
      " 17  author_handle                  88037 non-null  object\n",
      " 18  created_at                     88037 non-null  object\n",
      " 19  conversation_id                88037 non-null  int64 \n",
      " 20  possibly_sensitive             88037 non-null  bool  \n",
      " 21  reply_settings                 88037 non-null  object\n",
      " 22  source                         88037 non-null  object\n",
      " 23  author_follower_count          88037 non-null  int64 \n",
      " 24  retweet_count                  88037 non-null  int64 \n",
      " 25  reply_count                    88037 non-null  int64 \n",
      " 26  like_count                     88037 non-null  int64 \n",
      " 27  quote_count                    88037 non-null  int64 \n",
      " 28  replied_to                     88037 non-null  object\n",
      " 29  replied_to_author_id           88037 non-null  object\n",
      " 30  replied_to_handle              88037 non-null  object\n",
      " 31  replied_to_follower_count      88037 non-null  object\n",
      " 32  quoted                         88037 non-null  object\n",
      " 33  quoted_author_id               88037 non-null  object\n",
      " 34  quoted_handle                  88037 non-null  object\n",
      " 35  quoted_follower_count          88037 non-null  object\n",
      " 36  retweeted                      88037 non-null  object\n",
      " 37  retweeted_author_id            88037 non-null  object\n",
      " 38  retweeted_handle               88037 non-null  object\n",
      " 39  retweeted_follower_count       88037 non-null  object\n",
      " 40  mentioned_author_ids           88037 non-null  object\n",
      " 41  mentioned_handles              88037 non-null  object\n",
      " 42  hashtags                       88037 non-null  object\n",
      " 43  urls                           88037 non-null  object\n",
      " 44  media_keys                     88037 non-null  object\n",
      " 45  place_id                       88037 non-null  object\n",
      "dtypes: bool(11), int64(8), object(27)\n",
      "memory usage: 24.4+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9f7d82e",
   "metadata": {},
   "source": [
    "# How many tweets were posted containing the term on each day?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "64db2d09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          date  tweet_count\n",
      "0   2019-03-12            3\n",
      "1   2019-04-06            1\n",
      "2   2019-04-14            1\n",
      "3   2019-04-16            1\n",
      "4   2019-04-21            1\n",
      "5   2019-04-24            1\n",
      "6   2019-04-26            1\n",
      "7   2019-04-27            3\n",
      "8   2019-04-28           22\n",
      "9   2019-04-29          118\n",
      "10  2019-04-30          135\n",
      "11  2019-05-01           71\n",
      "12  2019-05-02           72\n",
      "13  2019-05-03          103\n",
      "14  2019-05-04           75\n",
      "15  2019-05-05           65\n",
      "16  2019-05-06           71\n",
      "17  2019-05-07           64\n",
      "18  2019-05-08           60\n",
      "19  2019-05-09           70\n",
      "20  2019-05-10          307\n",
      "21  2019-05-11           78\n",
      "22  2019-05-12           69\n",
      "23  2019-05-13           50\n",
      "24  2019-05-14           67\n",
      "25  2019-05-15           99\n",
      "26  2019-05-16           91\n",
      "27  2019-05-17          162\n",
      "28  2019-05-18           61\n",
      "29  2019-05-19           46\n",
      "30  2019-05-20           64\n",
      "31  2019-05-21          119\n",
      "32  2019-05-22           80\n",
      "33  2019-05-23           73\n",
      "34  2019-05-24           49\n",
      "35  2019-05-25           92\n",
      "36  2019-05-26          112\n",
      "37  2019-05-27           76\n",
      "38  2019-05-28           96\n",
      "39  2019-05-29          187\n",
      "40  2019-05-30           71\n",
      "41  2019-05-31           14\n"
     ]
    }
   ],
   "source": [
    "# Convert 'created_at' to datetime, with 'utc=True' for timezone-aware data, and coerce errors to NaT\n",
    "df['created_at'] = pd.to_datetime(df['created_at'], errors='coerce', utc=True)\n",
    "\n",
    "# Check if there are any rows where 'created_at' couldn't be converted\n",
    "invalid_dates = df[df['created_at'].isna()]\n",
    "if not invalid_dates.empty:\n",
    "    print(\"There are rows with invalid 'created_at' values:\")\n",
    "    print(invalid_dates[['created_at', 'text']])  # Display affected rows\n",
    "\n",
    "# Function to search for a term in the 'text' column and count occurrences by date\n",
    "def search_term_by_date(term, df):\n",
    "    # Filter rows where the 'text' column contains the search term (case-insensitive)\n",
    "    filtered_df = df[df['text'].str.contains(term, case=False, na=False)]\n",
    "    \n",
    "    # Remove rows with missing dates in 'created_at'\n",
    "    filtered_df = filtered_df[filtered_df['created_at'].notna()]\n",
    "    \n",
    "    # Extract the date from 'created_at' and group by date to count occurrences\n",
    "    result = filtered_df.groupby(filtered_df['created_at'].dt.date)['text'].count().reset_index()\n",
    "    \n",
    "    # Rename columns for clarity\n",
    "    result.columns = ['date', 'tweet_count']\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Example usage: Search for tweets containing the term \"music\"\n",
    "term = 'music'\n",
    "result = search_term_by_date(term, df)\n",
    "\n",
    "# Display the result\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2923428c",
   "metadata": {},
   "source": [
    "# How many unique users posted a tweet containing the term?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6759bc53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          date  tweet_count  unique_users\n",
      "0   2019-03-12            3             3\n",
      "1   2019-04-06            1             1\n",
      "2   2019-04-14            1             1\n",
      "3   2019-04-16            1             1\n",
      "4   2019-04-21            1             1\n",
      "5   2019-04-24            1             1\n",
      "6   2019-04-26            1             1\n",
      "7   2019-04-27            3             3\n",
      "8   2019-04-28           22            21\n",
      "9   2019-04-29          118            97\n",
      "10  2019-04-30          135           123\n",
      "11  2019-05-01           71            60\n",
      "12  2019-05-02           72            63\n",
      "13  2019-05-03          103            92\n",
      "14  2019-05-04           75            69\n",
      "15  2019-05-05           65            57\n",
      "16  2019-05-06           71            57\n",
      "17  2019-05-07           64            48\n",
      "18  2019-05-08           60            55\n",
      "19  2019-05-09           70            63\n",
      "20  2019-05-10          307           299\n",
      "21  2019-05-11           78            62\n",
      "22  2019-05-12           69            61\n",
      "23  2019-05-13           50            39\n",
      "24  2019-05-14           67            52\n",
      "25  2019-05-15           99            90\n",
      "26  2019-05-16           91            77\n",
      "27  2019-05-17          162           151\n",
      "28  2019-05-18           61            54\n",
      "29  2019-05-19           46            38\n",
      "30  2019-05-20           64            54\n",
      "31  2019-05-21          119           108\n",
      "32  2019-05-22           80            68\n",
      "33  2019-05-23           73            67\n",
      "34  2019-05-24           49            41\n",
      "35  2019-05-25           92            69\n",
      "36  2019-05-26          112            94\n",
      "37  2019-05-27           76            67\n",
      "38  2019-05-28           96            87\n",
      "39  2019-05-29          187           176\n",
      "40  2019-05-30           71            65\n",
      "41  2019-05-31           14            14\n"
     ]
    }
   ],
   "source": [
    "# Function to search for a term and count occurrences and unique users by date\n",
    "def search_term_by_date(term, df):\n",
    "    # Filter rows where the 'text' column contains the search term (case-insensitive)\n",
    "    filtered_df = df[df['text'].str.contains(term, case=False, na=False)]\n",
    "    \n",
    "    # Remove rows with missing dates in 'created_at'\n",
    "    filtered_df = filtered_df[filtered_df['created_at'].notna()]\n",
    "    \n",
    "    # Extract the date from 'created_at' and group by date\n",
    "    result = filtered_df.groupby(filtered_df['created_at'].dt.date).agg(\n",
    "        tweet_count=('text', 'count'),  # Count total tweets\n",
    "        unique_users=('author_id', pd.Series.nunique)  # Count unique users\n",
    "    ).reset_index()\n",
    "    \n",
    "    # Rename columns for clarity\n",
    "    result.columns = ['date', 'tweet_count', 'unique_users']\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Example usage: Search for tweets containing the term \"music\"\n",
    "term = 'music'\n",
    "result = search_term_by_date(term, df)\n",
    "\n",
    "# Display the result\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e3ef5a3",
   "metadata": {},
   "source": [
    "# How many likes did tweets containing the term get, on average?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "abadbcc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          date  tweet_count  unique_users    avg_likes\n",
      "0   2019-03-12            3             3  1293.666667\n",
      "1   2019-04-06            1             1   210.000000\n",
      "2   2019-04-14            1             1   969.000000\n",
      "3   2019-04-16            1             1     6.000000\n",
      "4   2019-04-21            1             1    14.000000\n",
      "5   2019-04-24            1             1     8.000000\n",
      "6   2019-04-26            1             1    54.000000\n",
      "7   2019-04-27            3             3    65.000000\n",
      "8   2019-04-28           22            21     0.954545\n",
      "9   2019-04-29          118            97    20.932203\n",
      "10  2019-04-30          135           123     1.074074\n",
      "11  2019-05-01           71            60     3.676056\n",
      "12  2019-05-02           72            63    34.708333\n",
      "13  2019-05-03          103            92     2.854369\n",
      "14  2019-05-04           75            69     2.840000\n",
      "15  2019-05-05           65            57     3.384615\n",
      "16  2019-05-06           71            57    51.070423\n",
      "17  2019-05-07           64            48     4.875000\n",
      "18  2019-05-08           60            55  1264.716667\n",
      "19  2019-05-09           70            63    12.085714\n",
      "20  2019-05-10          307           299    60.267101\n",
      "21  2019-05-11           78            62     1.038462\n",
      "22  2019-05-12           69            61     0.971014\n",
      "23  2019-05-13           50            39    26.300000\n",
      "24  2019-05-14           67            52     2.089552\n",
      "25  2019-05-15           99            90     2.767677\n",
      "26  2019-05-16           91            77    13.659341\n",
      "27  2019-05-17          162           151     3.135802\n",
      "28  2019-05-18           61            54    21.803279\n",
      "29  2019-05-19           46            38     6.826087\n",
      "30  2019-05-20           64            54     0.578125\n",
      "31  2019-05-21          119           108     3.000000\n",
      "32  2019-05-22           80            68     2.212500\n",
      "33  2019-05-23           73            67     0.191781\n",
      "34  2019-05-24           49            41   713.530612\n",
      "35  2019-05-25           92            69    12.619565\n",
      "36  2019-05-26          112            94     3.464286\n",
      "37  2019-05-27           76            67     0.315789\n",
      "38  2019-05-28           96            87   420.354167\n",
      "39  2019-05-29          187           176     1.320856\n",
      "40  2019-05-30           71            65  4094.098592\n",
      "41  2019-05-31           14            14     5.928571\n"
     ]
    }
   ],
   "source": [
    "# Function to search for a term and count occurrences, unique users, and average likes by date\n",
    "def search_term_by_date(term, df):\n",
    "    # Filter rows where the 'text' column contains the search term (case-insensitive)\n",
    "    filtered_df = df[df['text'].str.contains(term, case=False, na=False)]\n",
    "    \n",
    "    # Remove rows with missing dates in 'created_at'\n",
    "    filtered_df = filtered_df[filtered_df['created_at'].notna()]\n",
    "    \n",
    "    # Extract the date from 'created_at' and group by date\n",
    "    result = filtered_df.groupby(filtered_df['created_at'].dt.date).agg(\n",
    "        tweet_count=('text', 'count'),               # Count total tweets\n",
    "        unique_users=('author_id', pd.Series.nunique),  # Count unique users\n",
    "        avg_likes=('like_count', 'mean')             # Calculate average likes\n",
    "    ).reset_index()\n",
    "    \n",
    "    # Rename columns for clarity\n",
    "    result.columns = ['date', 'tweet_count', 'unique_users', 'avg_likes']\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Example usage: Search for tweets containing the term \"music\"\n",
    "term = 'music'\n",
    "result = search_term_by_date(term, df)\n",
    "\n",
    "# Display the result\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b02d8565",
   "metadata": {},
   "source": [
    "# Where (in terms of place IDs) did the tweets come from?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2546ee25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          date          place_id  tweet_count  unique_users    avg_likes\n",
      "0   2019-03-12              None            3             3  1293.666667\n",
      "1   2019-04-06              None            1             1   210.000000\n",
      "2   2019-04-14              None            1             1   969.000000\n",
      "3   2019-04-16              None            1             1     6.000000\n",
      "4   2019-04-21              None            1             1    14.000000\n",
      "..         ...               ...          ...           ...          ...\n",
      "79  2019-05-29  53504716d445dcad            1             1     0.000000\n",
      "80  2019-05-29              None          184           173     1.326087\n",
      "81  2019-05-29  ab2f2fac83aa388d            1             1     0.000000\n",
      "82  2019-05-30              None           71            65  4094.098592\n",
      "83  2019-05-31              None           14            14     5.928571\n",
      "\n",
      "[84 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "# Function to search for a term and count occurrences, unique users, average likes, and group by place ID\n",
    "def search_term_by_date_and_location(term, df):\n",
    "    # Filter rows where the 'text' column contains the search term (case-insensitive)\n",
    "    filtered_df = df[df['text'].str.contains(term, case=False, na=False)]\n",
    "    \n",
    "    # Remove rows with missing dates in 'created_at'\n",
    "    filtered_df = filtered_df[filtered_df['created_at'].notna()]\n",
    "    \n",
    "    # Extract the date from 'created_at' and group by date and place_id\n",
    "    result = filtered_df.groupby([filtered_df['created_at'].dt.date, 'place_id']).agg(\n",
    "        tweet_count=('text', 'count'),              # Count total tweets\n",
    "        unique_users=('author_id', pd.Series.nunique),  # Count unique users\n",
    "        avg_likes=('like_count', 'mean')            # Calculate average likes\n",
    "    ).reset_index()\n",
    "    \n",
    "    # Rename columns for clarity\n",
    "    result.columns = ['date', 'place_id', 'tweet_count', 'unique_users', 'avg_likes']\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Example usage: Search for tweets containing the term \"music\"\n",
    "term = 'music'\n",
    "result = search_term_by_date_and_location(term, df)\n",
    "\n",
    "# Display the result\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae4ffa2",
   "metadata": {},
   "source": [
    "# What times of day were the tweets posted at?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3c851f58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     time_of_day  tweet_count  unique_users  avg_likes\n",
      "0       00:00:37            1             1        0.0\n",
      "1       00:00:49            1             1        1.0\n",
      "2       00:00:57            1             1        0.0\n",
      "3       00:01:07            1             1        0.0\n",
      "4       00:01:16            1             1        0.0\n",
      "...          ...          ...           ...        ...\n",
      "2910    23:58:48            1             1        1.0\n",
      "2911    23:58:51            1             1        1.0\n",
      "2912    23:58:54            1             1        0.0\n",
      "2913    23:59:24            1             1        0.0\n",
      "2914    23:59:43            1             1        0.0\n",
      "\n",
      "[2915 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "# Function to search for a term and count occurrences, unique users, average likes, and group by time of day\n",
    "def search_term_by_time_of_day(term, df):\n",
    "    # Filter rows where the 'text' column contains the search term (case-insensitive)\n",
    "    filtered_df = df[df['text'].str.contains(term, case=False, na=False)]\n",
    "    \n",
    "    # Remove rows with missing dates in 'created_at'\n",
    "    filtered_df = filtered_df[filtered_df['created_at'].notna()]\n",
    "    \n",
    "    # Convert 'created_at' to datetime if not already done\n",
    "    filtered_df['created_at'] = pd.to_datetime(filtered_df['created_at'], errors='coerce')\n",
    "    \n",
    "    # Extract the time from 'created_at' and group by time of day\n",
    "    filtered_df['time_of_day'] = filtered_df['created_at'].dt.time\n",
    "    result = filtered_df.groupby('time_of_day').agg(\n",
    "        tweet_count=('text', 'count'),              # Count total tweets\n",
    "        unique_users=('author_id', pd.Series.nunique),  # Count unique users\n",
    "        avg_likes=('like_count', 'mean')            # Calculate average likes\n",
    "    ).reset_index()\n",
    "    \n",
    "    # Rename columns for clarity\n",
    "    result.columns = ['time_of_day', 'tweet_count', 'unique_users', 'avg_likes']\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Example usage: Search for tweets containing the term \"music\"\n",
    "term = 'music'\n",
    "result = search_term_by_time_of_day(term, df)\n",
    "\n",
    "# Display the result\n",
    "print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da1bd65b",
   "metadata": {},
   "source": [
    "# Which user posted the most tweets containing the term?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ce701af1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The most active user for the term 'music' is:\n",
      "User ID: 118301422, Handle: freqnetwork, Tweet Count: 90\n"
     ]
    }
   ],
   "source": [
    "# Function to search for a term and find the user who posted the most tweets\n",
    "def most_active_user(term, df):\n",
    "    # Filter rows where the 'text' column contains the search term (case-insensitive)\n",
    "    filtered_df = df[df['text'].str.contains(term, case=False, na=False)]\n",
    "    \n",
    "    # Count the number of tweets for each user\n",
    "    user_tweet_counts = filtered_df.groupby(['author_id', 'author_handle']).size().reset_index(name='tweet_count')\n",
    "    \n",
    "    # Find the user with the maximum tweet count\n",
    "    most_active = user_tweet_counts.loc[user_tweet_counts['tweet_count'].idxmax()]\n",
    "    \n",
    "    return most_active\n",
    "\n",
    "# Example usage: Search for tweets containing the term \"music\"\n",
    "term = 'music'\n",
    "result = most_active_user(term, df)\n",
    "\n",
    "# Display the result\n",
    "print(f\"The most active user for the term '{term}' is:\")\n",
    "print(f\"User ID: {result['author_id']}, Handle: {result['author_handle']}, Tweet Count: {result['tweet_count']}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
